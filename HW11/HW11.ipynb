{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fashion_mnist_gui.py\n",
    "import sys\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from PyQt6.QtWidgets import QApplication, QLabel, QVBoxLayout, QWidget, QFileDialog\n",
    "from PyQt6.QtCore import Qt, QSize\n",
    "from PyQt6.QtGui import QPixmap, QDragEnterEvent, QDropEvent\n",
    "\n",
    "class FashionMNISTClassifier(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Class names for Fashion MNIST\n",
    "        self.class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "                            'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "        \n",
    "        # Load TFLite model\n",
    "        self.interpreter = tf.lite.Interpreter(model_path='fashion_mnist.tflite')\n",
    "        self.interpreter.allocate_tensors()\n",
    "        self.input_details = self.interpreter.get_input_details()\n",
    "        self.output_details = self.interpreter.get_output_details()\n",
    "        \n",
    "        self.initUI()\n",
    "\n",
    "    def initUI(self):\n",
    "        self.setWindowTitle('Fashion MNIST Classifier')\n",
    "        self.setAcceptDrops(True)\n",
    "        self.setMinimumSize(QSize(400, 400))\n",
    "\n",
    "        layout = QVBoxLayout()\n",
    "        \n",
    "        # Image display\n",
    "        self.image_label = QLabel(\"Drag & Drop Image Here\")\n",
    "        self.image_label.setAlignment(Qt.AlignmentFlag.AlignCenter)\n",
    "        self.image_label.setStyleSheet(\"\"\"\n",
    "            QLabel {\n",
    "                border: 2px dashed #aaa;\n",
    "                padding: 20px;\n",
    "                background-color: #f0f0f0;\n",
    "            }\n",
    "        \"\"\")\n",
    "\n",
    "        # Prediction label\n",
    "        self.prediction_label = QLabel(\"Prediction: \")\n",
    "        self.prediction_label.setStyleSheet(\"font-size: 18px; font-weight: bold;\")\n",
    "        self.prediction_label.setAlignment(Qt.AlignmentFlag.AlignCenter)\n",
    "\n",
    "        layout.addWidget(self.image_label)\n",
    "        layout.addWidget(self.prediction_label)\n",
    "        self.setLayout(layout)\n",
    "\n",
    "    def dragEnterEvent(self, event: QDragEnterEvent):\n",
    "        if event.mimeData().hasUrls():\n",
    "            event.accept()\n",
    "        else:\n",
    "            event.ignore()\n",
    "\n",
    "    def dropEvent(self, event: QDropEvent):\n",
    "        file_path = event.mimeData().urls()[0].toLocalFile()\n",
    "        self.process_image(file_path)\n",
    "\n",
    "    def process_image(self, file_path):\n",
    "        try:\n",
    "            \"\"\"# Preprocess image\n",
    "            img = Image.open(file_path).convert('L').resize((28, 28))\n",
    "            img_array = np.array(img).reshape(1, 28, 28, 1).astype('float32') / 255.0\"\"\"\n",
    "\n",
    "            # Preprocess image\n",
    "            img = Image.open(file_path).convert('L').resize((28, 28))  # Convert to grayscale and resize\n",
    "            img_array = np.array(img, dtype=np.float32) / 255.0  # Normalize pixel values\n",
    "            img_array = np.expand_dims(img_array, axis=(0, -1))  # Add batch and channel dims\n",
    "\n",
    "            # Run inference\n",
    "            self.interpreter.set_tensor(self.input_details[0]['index'], img_array)\n",
    "            self.interpreter.invoke()\n",
    "            predictions = self.interpreter.get_tensor(self.output_details[0]['index'])\n",
    "            \n",
    "            # Display results\n",
    "            self.image_label.setPixmap(QPixmap(file_path).scaled(200, 200))\n",
    "            predicted_class = self.class_names[np.argmax(predictions)]\n",
    "            confidence = np.max(tf.nn.softmax(predictions))\n",
    "            self.prediction_label.setText(\n",
    "                f\"Prediction: {predicted_class}\\nConfidence: {confidence:.2%}\"\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            self.prediction_label.setText(f\"Error: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.7547 - loss: 0.6761 - val_accuracy: 0.8667 - val_loss: 0.3632\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - accuracy: 0.8844 - loss: 0.3222 - val_accuracy: 0.8738 - val_loss: 0.3474\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9001 - loss: 0.2711 - val_accuracy: 0.8966 - val_loss: 0.2808\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9111 - loss: 0.2383 - val_accuracy: 0.8980 - val_loss: 0.2812\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - accuracy: 0.9196 - loss: 0.2145 - val_accuracy: 0.9017 - val_loss: 0.2675\n",
      "INFO:tensorflow:Assets written to: /var/folders/d5/_b51qwzx4f7__pl7x_l5jnkw0000gn/T/tmpzeibqlo1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/d5/_b51qwzx4f7__pl7x_l5jnkw0000gn/T/tmpzeibqlo1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/var/folders/d5/_b51qwzx4f7__pl7x_l5jnkw0000gn/T/tmpzeibqlo1'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  4423065744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  4423066896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  4423063440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  4423064976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  4423066320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  4423065936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  4423065168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  4423065552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  4423067664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  4423068816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1739130393.034831 5988148 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1739130393.034850 5988148 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2025-02-09 20:46:33.035252: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/d5/_b51qwzx4f7__pl7x_l5jnkw0000gn/T/tmpzeibqlo1\n",
      "2025-02-09 20:46:33.035694: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-02-09 20:46:33.035699: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /var/folders/d5/_b51qwzx4f7__pl7x_l5jnkw0000gn/T/tmpzeibqlo1\n",
      "I0000 00:00:1739130393.039864 5988148 mlir_graph_optimization_pass.cc:401] MLIR V1 optimization pass is not enabled\n",
      "2025-02-09 20:46:33.040625: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-02-09 20:46:33.066719: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /var/folders/d5/_b51qwzx4f7__pl7x_l5jnkw0000gn/T/tmpzeibqlo1\n",
      "2025-02-09 20:46:33.074744: I tensorflow/cc/saved_model/loader.cc:466] SavedModel load for tags { serve }; Status: success: OK. Took 39497 microseconds.\n",
      "2025-02-09 20:46:33.082087: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Preprocess data\n",
    "#x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "#x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "\n",
    "x_train = x_train.reshape((x_train.shape[0], 28, 28, 1)).astype('float32') / 255\n",
    "x_test = x_test.reshape((x_test.shape[0], 28, 28, 1)).astype('float32') / 255\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(28, 28, 1)),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile and train\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy,#(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
    "\n",
    "# Convert to TFLite with quantization (OPTIONAL)\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "#converter.optimizations = [tf.lite.Optimize.DEFAULT]  # Quantization\n",
    "tflite_quant_model = converter.convert()\n",
    "\n",
    "# Save models\n",
    "with open('fashion_mnist.tflite', 'wb') as f:\n",
    "    f.write(tflite_quant_model)\n",
    "\n",
    "# Save model summary (for slides)\n",
    "with open('model_summary.txt', 'w') as f:\n",
    "    model.summary(print_fn=lambda x: f.write(x + '\\n'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "2025-02-09 20:46:33.477 python[94799:5988148] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-02-09 20:46:33.477 python[94799:5988148] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohitpotdukhe/Documents/UniDocs/DSSS 2025/DSSS_Assignments_New/.conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "app = QApplication(sys.argv)\n",
    "window = FashionMNISTClassifier()\n",
    "window.resize(400, 400)\n",
    "window.show()\n",
    "sys.exit(app.exec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
